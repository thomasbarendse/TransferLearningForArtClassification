{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "transfer_learning_art_classification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqJnZFuZw7mE",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Transfer Learning for Art Classification\n",
        "==========================\n",
        "**Authors**: Jasper van Tilburg, Martijn Bosma, Thomas Barendse\n",
        "\n",
        "In this notebook, we intend to reproduce results of the paper by Sabatelli et. al []. We apply two Transfer Learning (TL) procedures to the Rijksmuseum dataset used in the paper, as well as a subset of the iMet dataset (see [link to kaggle]). \n",
        "\n",
        "The following code is mainly based on two other attempts at TL:\n",
        "- https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html\n",
        "- https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\n",
        "\n",
        "These two major TL procedures look as follows:\n",
        "\n",
        "-  **Finetuning**: Taking the parameters of the model trained on ImageNet as a starting point, we train all parameters of the model further on our dataset.\n",
        "-  **Off-the-shelf**: Taking the parameters of the model trained on ImageNet as a starting point, we only retrain the last softmax layer of the network. All other parameters remain the same.\n",
        "\n",
        "The aim of the reproduction is to verify the results presented in the paper.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4m-UaDvNZtx",
        "colab_type": "text"
      },
      "source": [
        "Importing data from Kaggle\n",
        "--------------------------\n",
        "\n",
        "The following link describes how to get a token in order to import the data from kaggle: https://www.kaggle.com/general/74235"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRGSXNIew7lx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "riz5x8kFqAvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install -q kaggle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjpacaMCxCT9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "files.upload()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hmye2mh_yHue",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! mkdir ~/.kaggle\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkiYSu7GyvRD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d 'martybosma/rijksbymaterialfiltered' -p /content\n",
        "!unzip \\*.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1iBQX19yNifc",
        "colab_type": "text"
      },
      "source": [
        "Python imports\n",
        "--------------"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8iklVqk8w7mH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "\n",
        "plt.ion()   # interactive mode"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0rA7273sw7mR",
        "colab_type": "text"
      },
      "source": [
        "Preprocessing the Data\n",
        "---------\n",
        "\n",
        "We use torch.utils.data.DataLoader to load the data such that it can be used for training. Minimal data transformation is applied, but most importantly, pixel values are mapped to the [0,1]-interval, done by tranforms.ToTensor().\n",
        "\n",
        "We also initialise Colab's GPU for training.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J_4O6bJiw7mW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = './rijks_by_material_filtered/rijks_jpg/'\n",
        "\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir, x),\n",
        "                                          data_transforms[x])\n",
        "                  for x in ['train', 'val']}\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], batch_size=32,\n",
        "                                             shuffle=True, num_workers=4)\n",
        "              for x in ['train', 'val']}\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1oqYPsVhw7mp",
        "colab_type": "text"
      },
      "source": [
        "Training the model\n",
        "------------------\n",
        "\n",
        "The following function retrains the initialised model on the provided dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjSYy9ODw7mz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "    since = time.time()\n",
        "    time_elapsed = 0\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
        "                phase, epoch_loss, epoch_acc))\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        \n",
        "        epoch_time = time.time() - time_elapsed - since\n",
        "        time_elapsed = time.time() - since\n",
        "        print('Epoch complete in {:.0f}m {:.0f}s'.format(\n",
        "              epoch_time // 60, time_elapsed % 60))\n",
        "        print('Total time {:.0f}m {:.0f}s'.format(\n",
        "              time_elapsed // 60, time_elapsed % 60))\n",
        "\n",
        "    print('Best val Acc: {:4f}'.format(best_acc))\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQyu5w7SPtEI",
        "colab_type": "text"
      },
      "source": [
        "Importing a pretrained model\n",
        "----------------------------\n",
        "\n",
        "Functions to import a pretrained model and specify whether to freeze its parameters, referred to as feature extraction (True means freeze)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Eh6yrcRrBuR2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def set_parameter_requires_grad(model, feature_extracting):\n",
        "    if feature_extracting:\n",
        "        for param in model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "def initialize_model(model_name, num_classes, feature_extract, use_pretrained=True):\n",
        "    # Initialize these variables which will be set in this if statement. Each of these\n",
        "    #   variables is model specific.\n",
        "    model_ft = None\n",
        "\n",
        "    if model_name == \"resnet\":\n",
        "        \"\"\" Resnet50\n",
        "        \"\"\"\n",
        "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.fc.in_features\n",
        "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
        "\n",
        "    elif model_name == \"alexnet\":\n",
        "        \"\"\" Alexnet\n",
        "        \"\"\"\n",
        "        model_ft = models.alexnet(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "\n",
        "    elif model_name == \"vgg\":\n",
        "        \"\"\" VGG11_bn\n",
        "        \"\"\"\n",
        "        model_ft = models.vgg11_bn(pretrained=use_pretrained)\n",
        "        set_parameter_requires_grad(model_ft, feature_extract)\n",
        "        num_ftrs = model_ft.classifier[6].in_features\n",
        "        model_ft.classifier[6] = nn.Linear(num_ftrs,num_classes)\n",
        "\n",
        "    return model_ft"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJd2kRpGw7nI",
        "colab_type": "text"
      },
      "source": [
        "Finetuning TL\n",
        "----------------------\n",
        "\n",
        "Load a pretrained model and allow for retraining all parameters (feature_extract = False). We use the cross entropy loss, and stochastic gradient descent with the parameters as specified in the paper.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPvp3bMXw7nL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'alexnet' \n",
        "num_classes = len(class_names)\n",
        "\n",
        "model_ft = initialize_model(model_name, num_classes, feature_extract=False, use_pretrained=True)\n",
        "\n",
        "model_ft = model_ft.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Observe that all parameters are being optimized\n",
        "optimizer_ft = optim.SGD(model_ft.parameters(), lr=0.001, momentum=0.9, nesterov=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IzXw6xM-w7nU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ft = train_model(model_ft, criterion, optimizer_ft, num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtcESzpfw7nl",
        "colab_type": "text"
      },
      "source": [
        "\"Off-the-shelf\" TL\n",
        "----------------------------------\n",
        "\n",
        "We now set feature_extract = True, such that only the final softmax layers is retrained. We use the same loss function, but for optimisation we now use RMSProp, as the authors of the paper did."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTo4Oy2Ew7no",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_name = 'resnet' \n",
        "num_classes = len(class_names)\n",
        "\n",
        "model_ots = initialize_model(model_name, num_classes, feature_extract=True, use_pretrained=True)\n",
        "\n",
        "model_ots = model_ots.to(device)\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer_ots = optim.RMSprop([param for param in model_ots.parameters() if param.requires_grad == True], \n",
        "                               lr=0.001, eps=1e-08, momentum=0.9)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qaHDVZEw7nz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ots = train_model(model_ots, criterion, optimizer_ots, num_epochs=25)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}